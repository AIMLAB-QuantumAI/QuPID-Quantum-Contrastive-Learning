{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8511fb7-4e69-4298-a909-a73debd6d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pennylane as qml\n",
    "import timm\n",
    "\n",
    "\n",
    "class ViTEncoder(nn.Module):\n",
    "    def __init__(self, model_name='vit_large_patch16_224', embedding_dim=1024,\n",
    "                 pretrained=True, freeze_backbone=True):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n",
    "        self.vit_dim = self.vit.embed_dim\n",
    "        self.freeze_backbone = freeze_backbone\n",
    "        if freeze_backbone:\n",
    "            for param in self.vit.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.vit_dim, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, embedding_dim)\n",
    "        )\n",
    "        self.n_trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    \n",
    "    def forward(self, x, return_features=False):\n",
    "        if self.freeze_backbone:\n",
    "            self.vit.eval()\n",
    "            with torch.no_grad():\n",
    "                features = self.vit(x)\n",
    "        else:\n",
    "            features = self.vit(x)\n",
    "        if return_features:\n",
    "            return features\n",
    "        embedding = self.projector(features)\n",
    "        return F.normalize(embedding, dim=1)\n",
    "\n",
    "\n",
    "class QuantumEnhancer(nn.Module):\n",
    "    def __init__(self, input_dim=1024, n_qubits=10, n_qlayers=3):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_qlayers = n_qlayers\n",
    "        self.quantum_dim = 2 ** n_qubits\n",
    "        self.projection = nn.Linear(input_dim, self.quantum_dim, bias=True)\n",
    "        nn.init.xavier_uniform_(self.projection.weight)\n",
    "        dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "        \n",
    "        @qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
    "        def quantum_circuit(inputs, weights):\n",
    "            qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True)\n",
    "            qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "            return qml.state()\n",
    "        \n",
    "        weight_shape = qml.templates.BasicEntanglerLayers.shape(\n",
    "            n_layers=n_qlayers, n_wires=n_qubits\n",
    "        )\n",
    "        self.quantum_layer = qml.qnn.TorchLayer(quantum_circuit, {\"weights\": weight_shape})\n",
    "        self.n_trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    \n",
    "    def forward(self, embeddings):\n",
    "        projected = self.projection(embeddings)\n",
    "        quantum_state = self.quantum_layer(projected)\n",
    "        quantum_amplitudes = torch.abs(quantum_state)\n",
    "        return quantum_amplitudes\n",
    "\n",
    "\n",
    "class QuPIDModel(nn.Module):\n",
    "    def __init__(self, vit_encoder, quantum_enhancer):\n",
    "        super().__init__()\n",
    "        self.vit_encoder = vit_encoder\n",
    "        self.quantum_enhancer = quantum_enhancer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        vit_embedding = self.vit_encoder(x)\n",
    "        quantum_amplitudes = self.quantum_enhancer(vit_embedding)\n",
    "        return quantum_amplitudes\n",
    "    \n",
    "    def get_vit_embedding(self, x):\n",
    "        return self.vit_encoder(x)\n",
    "\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature=0.07):\n",
    "    batch_size = z1.shape[0]\n",
    "    z = torch.cat([z1, z2], dim=0)\n",
    "    sim_matrix = torch.matmul(z, z.T) / temperature\n",
    "    mask = torch.eye(2 * batch_size, device=z.device, dtype=torch.bool)\n",
    "    sim_matrix.masked_fill_(mask, -1e9)\n",
    "    pos_sim = torch.cat([\n",
    "        torch.diag(sim_matrix, batch_size),\n",
    "        torch.diag(sim_matrix, -batch_size)\n",
    "    ])\n",
    "    exp_sim = torch.exp(sim_matrix)\n",
    "    loss = -torch.log(torch.exp(pos_sim) / exp_sim.sum(dim=1)).mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def quantum_contrastive_loss(q_state1, q_state2, temperature=0.07):\n",
    "    batch_size = q_state1.shape[0]\n",
    "    q_state1 = F.normalize(q_state1, dim=-1)\n",
    "    q_state2 = F.normalize(q_state2, dim=-1)\n",
    "    fidelity_matrix = torch.matmul(q_state1, q_state2.T) ** 2\n",
    "    logits = fidelity_matrix / temperature\n",
    "    labels = torch.arange(batch_size, device=q_state1.device)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def combined_contrastive_loss(z1, z2, q1, q2, temperature=0.07, quantum_weight=0.5):\n",
    "    classical_loss = nt_xent_loss(z1, z2, temperature)\n",
    "    quantum_loss = quantum_contrastive_loss(q1, q2, temperature)\n",
    "    total_loss = (1 - quantum_weight) * classical_loss + quantum_weight * quantum_loss\n",
    "    return total_loss, classical_loss, quantum_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
